{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##предварительная обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Чтение датасета с текстом\n",
    "df = pd.read_csv(\"reviews.csv\", encoding='UTF8', sep=\"\\t\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive\n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive\n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[1]]\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    товар отдали другому человеку, я не получила п...\n",
       "2    ужасная синтетика! тонкая, ничего общего с пре...\n",
       "3    товар не пришел, продавец продлил защиту без м...\n",
       "4        кофточка голая синтетика, носить не возможно.\n",
       "Name: text_lower, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Нижний регистр. Например, Товар --> товар, УРА --> ура\n",
    "df['text_lower']  = df['review'].str.lower()\n",
    "df['text_lower'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "      <td>товар отдали другому человеку, я не получила п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ужасная синтетика! тонкая, ничего общего с пре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "      <td>кофточка голая синтетика, носить не возможно.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
       "1  Товар отдали другому человеку, я не получила п...  negative   \n",
       "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
       "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
       "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
       "\n",
       "                                          text_lower  \n",
       "0  качество плохое пошив ужасный (горловина напер...  \n",
       "1  товар отдали другому человеку, я не получила п...  \n",
       "2  ужасная синтетика! тонкая, ничего общего с пре...  \n",
       "3  товар не пришел, продавец продлил защиту без м...  \n",
       "4      кофточка голая синтетика, носить не возможно.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    Товар отдали другому человеку, я не получила п...\n",
       "2    Ужасная синтетика! Тонкая, ничего общего с пре...\n",
       "3    товар не пришел, продавец продлил защиту без м...\n",
       "4        Кофточка голая синтетика, носить не возможно.\n",
       "Name: text_punct, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление пунктуации\n",
    "df['text_punct'] = df['review'].str.replace('[^\\w\\s]','')\n",
    "df['text_punct'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "#print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    Товар отдали другому человеку, получила посылк...\n",
       "2    Ужасная синтетика! Тонкая, общего представленн...\n",
       "3    товар пришел, продавец продлил защиту моего со...\n",
       "4           Кофточка голая синтетика, носить возможно.\n",
       "Name: text_stop, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление стоп-слов\n",
    "#Импорт стоп-слов из бибилиотеки nltk\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('russian'))\n",
    "# функция, удаляющая стопслова из текстов\n",
    "\n",
    "def stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "# Применим функцию удаления стоп-слов\n",
    "df[\"text_stop\"] = df[\"text_punct\"].apply(stopwords)\n",
    "df[\"text_stop\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('очень', 21054),\n",
       " ('размер', 13953),\n",
       " (',', 7945),\n",
       " ('деньги', 7917),\n",
       " ('продавец', 7195),\n",
       " ('На', 7174),\n",
       " ('это', 6822),\n",
       " ('товар', 6755),\n",
       " ('-', 6536),\n",
       " ('качество', 6499)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление высокочастотных слов\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_stop\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    плохое пошив ужасный (горловина наперекос) Фот...\n",
       "1    Товар отдали другому человеку, получила посылк...\n",
       "2    Ужасная синтетика! Тонкая, общего представленн...\n",
       "3    пришел, продлил защиту моего согласия. продавц...\n",
       "4           Кофточка голая синтетика, носить возможно.\n",
       "Name: text_common, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ужаление часто встречающиеся слов в корпусе при помощи tf-idf\n",
    "# Удаление самых частотных слов\n",
    "freq = set([w for (w, wc) in cnt.most_common(10)])\n",
    "# функция удаления слов\n",
    "def freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not \n",
    "in freq])\n",
    "# применение функции\n",
    "df[\"text_common\"] = df[\"text_stop\"].apply(freqwords)\n",
    "df[\"text_common\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    плохое пошив ужасный (горловина наперекос) Фот...\n",
       "1    Товар отдали другому человеку, получила посылк...\n",
       "2    Ужасная синтетика! Тонкая, общего представленн...\n",
       "3    пришел, продлил защиту моего согласия. продавц...\n",
       "4           Кофточка голая синтетика, носить возможно.\n",
       "Name: text_rare, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление низкочастотных слов\n",
    "freq = pd.Series(' '.join(df['text_common']).split()).value_counts()[-10:] # 10 rare words\n",
    "freq = list(freq.index)\n",
    "df['text_rare'] = df['text_common'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['text_rare'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление эмодзи\n",
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "#passing the emoji function to 'text_rare'\n",
    "df['text_rare'] = df['text_rare'].apply(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    плохое пошив ужасный (горловина наперекос) Фот...\n",
       "1    Товар отдали другому человеку, получила посылк...\n",
       "2    Ужасная синтетика! Тонкая, общего представленн...\n",
       "3    пришел, продлил защиту моего согласия. продавц...\n",
       "4           Кофточка голая синтетика, носить возможно.\n",
       "Name: text_nonum, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление цифр\n",
    "df['text_nonum'] = df['text_common'].str.replace('\\d+', '') \n",
    "df['text_nonum'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление URL\n",
    "# Function for url's\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "# Examples\n",
    "text = \"This is my website, https://www.link.com\"\n",
    "remove_urls(text)\n",
    "#Passing the function to 'text_rare'\n",
    "df['text_rare'] = df['text_rare'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Это \n",
      " странца\n",
      " пример\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Удаление HTML-тегов\n",
    "from bs4 import BeautifulSoup\n",
    "#Function for removing html\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "# Examples\n",
    "text = \"\"\"<div>\n",
    "<h1> Это </h1>\n",
    "<p> странца</p>\n",
    "<a href=\"https://www.link.com/\"> пример</a>\n",
    "</div>\n",
    "\"\"\"\n",
    "print(html(text))\n",
    "# Passing the function to 'text_rare'\n",
    "df['text_rare'] = df['text_rare'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[плохое, пошив, ужасный, горловина, наперекос,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[товар, отдали, другому, человеку, получила, п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ужасная, синтетика, тонкая, общего, представл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[пришел, продлил, защиту, моего, согласия, про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[кофточка, голая, синтетика, носить, возможно, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_token\n",
       "0  [плохое, пошив, ужасный, горловина, наперекос,...\n",
       "1  [товар, отдали, другому, человеку, получила, п...\n",
       "2  [ужасная, синтетика, тонкая, общего, представл...\n",
       "3  [пришел, продлил, защиту, моего, согласия, про...\n",
       "4   [кофточка, голая, синтетика, носить, возможно, ]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Токенизация\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "# Passing the function to 'text_rare' and store into'text_token'\n",
    "df['text_token'] = df['text_rare'].apply(lambda x: tokenization(x.lower()))\n",
    "df[['text_token']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>плохой пошив ужасный горловина наперекос фото ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдать другой человек получить посылка л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасный синтетик тонкий общий представить карт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>прийти продлить защита мой согласие продавец о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голый синтетик носить возможно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_lemm\n",
       "0  плохой пошив ужасный горловина наперекос фото ...\n",
       "1  товар отдать другой человек получить посылка л...\n",
       "2  ужасный синтетик тонкий общий представить карт...\n",
       "3  прийти продлить защита мой согласие продавец о...\n",
       "4            кофточка голый синтетик носить возможно"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Можно выполнить при помощи NLTK. Заодно проведем лемматизацию\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "\n",
    "def tokenize_lemmas(sent, pat=r\"(?u)\\b\\w\\w+\\b\", morph=MorphAnalyzer()):\n",
    "    return [morph.parse(tok)[0].normal_form \n",
    "            for tok in regexp_tokenize(sent, pat)]\n",
    "df[\"text_lemm\"] = df[\"text_rare\"].map(lambda x: \" \".join(tokenize_lemmas(x)))\n",
    "df[['text_lemm']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохой пошив ужасный горловина напере...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдать другой человек получить посылка л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасный синтетик тонкий общий представить карт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар прийти продавец продлить защита мой согл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голый синтетик носить возможно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_ready\n",
       "0  качество плохой пошив ужасный горловина напере...\n",
       "1  товар отдать другой человек получить посылка л...\n",
       "2  ужасный синтетик тонкий общий представить карт...\n",
       "3  товар прийти продавец продлить защита мой согл...\n",
       "4            кофточка голый синтетик носить возможно"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Исходя из цели автоматической обработки текста, выберем необходимые варианты предобработки текста. \n",
    "#Например, для классификации можно воспользоваться нижним регистром, удалением  пунктуации, ссылок, стоп-слов, \n",
    "#произвести лемматизацию и токенизацию\n",
    "##ИЛИ воспользоваться только удалением ссылок. Т.к. это актуальнее для НС, а выбор предобработки сделал для Машинного обученя\n",
    "df['text_ready']  = df['review'].str.lower()\n",
    "df['text_ready'] = df['text_ready'].str.replace('\\d+', '') \n",
    "df['text_ready'] = df['text_ready'].str.replace('[^\\w\\s]','')\n",
    "df[\"text_ready\"] = df[\"text_ready\"].apply(stopwords)\n",
    "df['text_ready'] = df['text_ready'].apply(emoji)\n",
    "df['text_ready'] = df['text_ready'].apply(remove_urls)\n",
    "df['text_ready'] = df['text_ready'].apply(html)\n",
    "df[\"text_ready\"] = df[\"text_ready\"].map(lambda x: \" \".join(tokenize_lemmas(x)))\n",
    "df[['text_ready']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Пример препобученной модели HuggingFace Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошая погода! Наконец-то тепло!\n"
     ]
    }
   ],
   "source": [
    "#txt = df.iloc[2,2]\n",
    "txt = \"Хорошая погода! Наконец-то тепло!\"\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predict(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
