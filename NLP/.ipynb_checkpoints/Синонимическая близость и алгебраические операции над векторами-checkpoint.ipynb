{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Синонимическая близость и алгебраические операции над векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative\n",
       "1  Товар отдали другому человеку, я не получила п...  negative\n",
       "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
       "3  товар не пришел, продавец продлил защиту без м...  negative\n",
       "4      Кофточка голая синтетика, носить не возможно.  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Чтение датасета с текстом\n",
    "df = pd.read_csv(\"reviews.csv\", encoding='UTF8', sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('russian'))\n",
    "# функция, удаляющая стопслова из текстов\n",
    "def stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "# Удаление эмодзи\n",
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "#Удаление URL\n",
    "# Function for url's\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "from bs4 import BeautifulSoup\n",
    "#Function for removing html\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "#Можно выполнить при помощи NLTK. Заодно проведем лемматизацию\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "\n",
    "def tokenize_lemmas(sent, pat=r\"(?u)\\b\\w\\w+\\b\", morph=MorphAnalyzer()):\n",
    "    return [morph.parse(tok)[0].normal_form \n",
    "            for tok in regexp_tokenize(sent, pat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['text_ready']  = df['review'].str.lower()\n",
    "df['text_ready'] = df['text_ready'].str.replace('\\d+', '') \n",
    "df['text_ready'] = df['text_ready'].str.replace('[^\\w\\s]','')\n",
    "df[\"text_ready\"] = df[\"text_ready\"].apply(stopwords)\n",
    "df['text_ready'] = df['text_ready'].apply(emoji)\n",
    "df['text_ready'] = df['text_ready'].apply(remove_urls)\n",
    "df['text_ready'] = df['text_ready'].apply(html)\n",
    "df[\"text_ready\"] = df[\"text_ready\"].map(lambda x: \" \".join(tokenize_lemmas(x)))\n",
    "df[['text_ready']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    min_count=5,\n",
    "    window=5,\n",
    "    vector_size=1000,\n",
    "    negative=5,\n",
    "    workers=24,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    sample=6e-5,\n",
    "    sg=1)\n",
    "#vector_size — размер векторного представления слова (word embedding).\n",
    "#negative — сколько неконтекстных слов учитывать в обучении, используя negative sampling.\n",
    "#alpha — начальный learning_rate, используемый в алгоритме обратного распространения ошибки (Backpropogation).\n",
    "#min_alpha — минимальное значение learning_rate, на которое может опуститься в процессе обучения.\n",
    "#sg — если 1, то используется реализация Skip-gram; если 0, то CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получаем лист слов\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, docs):\n",
    "        self.corpus = docs\n",
    "    def __iter__(self):\n",
    "        for doc in self.corpus:\n",
    "            doc_sentences = sent_tokenize(doc)\n",
    "            for sent in doc_sentences:\n",
    "                yield simple_preprocess(sent) # yields a tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MySentences(df['text_ready'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получаем словарь\n",
    "w2v_model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2297195, 6230855)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучение\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=5, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILLA_0\\AppData\\Local\\Temp\\ipykernel_35944\\232342886.py:2: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#для сохранения оперативной памяти можно написать следующее\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('исполнение', 0.9313054084777832),\n",
       " ('достойный', 0.9233419895172119),\n",
       " ('пошив', 0.912378191947937),\n",
       " ('троечка', 0.9075065851211548),\n",
       " ('ужасный', 0.9003157615661621),\n",
       " ('дизайн', 0.8915843963623047),\n",
       " ('оправдывать', 0.8891171216964722),\n",
       " ('много', 0.8866321444511414),\n",
       " ('превзойти', 0.8861345648765564),\n",
       " ('целое', 0.88553786277771),\n",
       " ('среднее', 0.8852310180664062),\n",
       " ('отстой', 0.8849294185638428),\n",
       " ('отвратительный', 0.8835281729698181),\n",
       " ('специфический', 0.8822568655014038),\n",
       " ('вышивка', 0.8808461427688599),\n",
       " ('хороший', 0.8799660801887512),\n",
       " ('аккуратный', 0.8794497847557068),\n",
       " ('ужасно', 0.8789946436882019),\n",
       " ('разочаровать', 0.8778073787689209),\n",
       " ('нюанс', 0.8761603832244873),\n",
       " ('недорогой', 0.8760831356048584),\n",
       " ('твёрдый', 0.8748862743377686),\n",
       " ('безобразный', 0.8748284578323364),\n",
       " ('тройка', 0.8741543292999268),\n",
       " ('ужас', 0.8734679222106934),\n",
       " ('ровненький', 0.8730788230895996),\n",
       " ('оправдаться', 0.8694702982902527),\n",
       " ('плохо', 0.8691617250442505),\n",
       " ('ужастный', 0.8674141764640808),\n",
       " ('блузочка', 0.8671914339065552)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"плохой\"], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('недовольный', 0.957168459892273),\n",
       " ('данный', 0.9529786109924316),\n",
       " ('впустую', 0.9503268003463745),\n",
       " ('удовлетворить', 0.9482129812240601),\n",
       " ('оперативный', 0.9402514100074768),\n",
       " ('продукция', 0.9395933151245117),\n",
       " ('переплатить', 0.9392696619033813),\n",
       " ('вздумать', 0.9376224279403687),\n",
       " ('алик', 0.934400200843811),\n",
       " ('крайне', 0.9342625737190247),\n",
       " ('успех', 0.9341805577278137),\n",
       " ('редко', 0.9341460466384888),\n",
       " ('процветание', 0.9340158700942993),\n",
       " ('продовца', 0.9331540465354919),\n",
       " ('говориться', 0.9329073429107666),\n",
       " ('чудесный', 0.9322918653488159),\n",
       " ('надобность', 0.9314894676208496),\n",
       " ('приобретать', 0.9305593967437744),\n",
       " ('встречать', 0.9296088218688965),\n",
       " ('ответственный', 0.9293996095657349),\n",
       " ('советовать', 0.928821861743927),\n",
       " ('акция', 0.9287900328636169),\n",
       " ('прадавец', 0.9283174276351929),\n",
       " ('благодарить', 0.9259511232376099),\n",
       " ('прадовец', 0.9258933067321777),\n",
       " ('тавар', 0.925376296043396),\n",
       " ('повториться', 0.9251278042793274),\n",
       " ('сожалеть', 0.9241697192192078),\n",
       " ('благодарный', 0.9237532019615173),\n",
       " ('респект', 0.9235981702804565),\n",
       " ('совесть', 0.9235445261001587),\n",
       " ('разочарованный', 0.9233248829841614),\n",
       " ('оправдаться', 0.9226247072219849),\n",
       " ('умница', 0.9225139021873474),\n",
       " ('притензия', 0.9224169850349426),\n",
       " ('бренд', 0.9220331907272339),\n",
       " ('оценить', 0.9212990403175354),\n",
       " ('блейзер', 0.920663595199585),\n",
       " ('копейка', 0.9205217361450195),\n",
       " ('сюрприз', 0.9204067587852478),\n",
       " ('никогда', 0.9201173186302185),\n",
       " ('позор', 0.9197388291358948),\n",
       " ('нужда', 0.919407844543457),\n",
       " ('профиль', 0.9184291362762451),\n",
       " ('доплатить', 0.9179060459136963),\n",
       " ('напрасно', 0.9178935289382935),\n",
       " ('конкретно', 0.9177559018135071),\n",
       " ('ход', 0.9173576831817627),\n",
       " ('супруг', 0.9172581434249878),\n",
       " ('рекомендоваться', 0.9161248207092285)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"товар\", \"продукт\", \"покупка\"], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('подождать', 0.929436206817627),\n",
       " ('продливать', 0.9276444911956787),\n",
       " ('истечение', 0.9271001815795898),\n",
       " ('истечь', 0.9257864952087402),\n",
       " ('продлять', 0.9252380132675171),\n",
       " ('обещание', 0.9207658171653748),\n",
       " ('уговаривать', 0.9195641875267029),\n",
       " ('отказываться', 0.9153127670288086),\n",
       " ('прождать', 0.9152768850326538),\n",
       " ('обострение', 0.9151750802993774),\n",
       " ('продление', 0.9151591062545776),\n",
       " ('дождаться', 0.9151166081428528),\n",
       " ('скоро', 0.9107868075370789),\n",
       " ('дважды', 0.9076015949249268),\n",
       " ('вернуться', 0.9055690765380859),\n",
       " ('автоматически', 0.9049137830734253),\n",
       " ('открытие', 0.9043081998825073),\n",
       " ('ведомо', 0.9041672945022583),\n",
       " ('завтрак', 0.9040720462799072),\n",
       " ('защита', 0.903617799282074),\n",
       " ('соглашаться', 0.9034237861633301),\n",
       " ('умолять', 0.903075098991394),\n",
       " ('прошлый', 0.9022698402404785),\n",
       " ('вмешательство', 0.9019907712936401),\n",
       " ('терпеливо', 0.901509702205658),\n",
       " ('длиться', 0.9012603163719177),\n",
       " ('поступить', 0.9011702537536621),\n",
       " ('возвращать', 0.9010085463523865),\n",
       " ('терпение', 0.899664580821991),\n",
       " ('привлечение', 0.898921549320221),\n",
       " ('молча', 0.8983041048049927),\n",
       " ('продлевать', 0.897585391998291),\n",
       " ('выиграть', 0.8975099921226501),\n",
       " ('истекать', 0.8962382078170776),\n",
       " ('закрытие', 0.8948343992233276),\n",
       " ('продлить', 0.894521951675415),\n",
       " ('споровый', 0.8945016264915466),\n",
       " ('всячески', 0.8940695524215698),\n",
       " ('спустя', 0.8936334252357483),\n",
       " ('уступка', 0.8932535648345947),\n",
       " ('убеждать', 0.8931787014007568),\n",
       " ('вновь', 0.8903056979179382),\n",
       " ('честность', 0.890191912651062),\n",
       " ('согласие', 0.8900763392448425),\n",
       " ('слёзно', 0.889539361000061),\n",
       " ('перестать', 0.8893076181411743),\n",
       " ('подтверждать', 0.8887677788734436),\n",
       " ('спорый', 0.888535737991333),\n",
       " ('окончание', 0.8873807191848755),\n",
       " ('закрыть', 0.886615514755249),\n",
       " ('контакт', 0.8866016268730164),\n",
       " ('принимать', 0.8855654001235962),\n",
       " ('закрыться', 0.885429322719574),\n",
       " ('подключиться', 0.8843401670455933),\n",
       " ('мозги', 0.8840371966362),\n",
       " ('потребовать', 0.883654773235321),\n",
       " ('неохотно', 0.8835892677307129),\n",
       " ('потерянный', 0.8830915689468384),\n",
       " ('апрель', 0.8829070329666138),\n",
       " ('уверять', 0.8827928304672241),\n",
       " ('клясться', 0.8825299739837646),\n",
       " ('кончиться', 0.8809819221496582),\n",
       " ('март', 0.8809802532196045),\n",
       " ('кормить', 0.8805786371231079),\n",
       " ('завершить', 0.8799871802330017),\n",
       " ('закончиться', 0.8792726993560791),\n",
       " ('надоесть', 0.8791391253471375),\n",
       " ('уговор', 0.8789347410202026),\n",
       " ('гарантия', 0.8789299130439758),\n",
       " ('завершиться', 0.8788889050483704),\n",
       " ('игнорил', 0.8787301182746887),\n",
       " ('конечный', 0.8779224157333374),\n",
       " ('стадия', 0.8773564100265503),\n",
       " ('принятие', 0.8772998452186584),\n",
       " ('арбитраж', 0.8770591616630554),\n",
       " ('успокаивать', 0.8764321208000183),\n",
       " ('денежка', 0.8758550882339478),\n",
       " ('завершение', 0.8756913542747498),\n",
       " ('ссылаться', 0.8752590417861938),\n",
       " ('реагировать', 0.875178337097168),\n",
       " ('установленный', 0.8744285106658936),\n",
       " ('диспут', 0.8743973970413208),\n",
       " ('подтверждение', 0.8741834759712219),\n",
       " ('игнора', 0.874052107334137),\n",
       " ('происходить', 0.8740060925483704),\n",
       " ('обещать', 0.8738529682159424),\n",
       " ('пришол', 0.8737101554870605),\n",
       " ('отменять', 0.8735904097557068),\n",
       " ('встреча', 0.8735662698745728),\n",
       " ('ворачивать', 0.872978687286377),\n",
       " ('ждать', 0.8724712133407593),\n",
       " ('признать', 0.8724634647369385),\n",
       " ('охотно', 0.8718585968017578),\n",
       " ('возвратить', 0.8714907169342041),\n",
       " ('покинуть', 0.8710812330245972),\n",
       " ('уговорить', 0.8710625171661377),\n",
       " ('заверить', 0.8710281848907471),\n",
       " ('зависнуть', 0.8707902431488037),\n",
       " ('улететь', 0.8706605434417725),\n",
       " ('затеряться', 0.8702459335327148)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Векторы можно складывать и вычитать. Например, рассмотрим такой вариант: “товар” + “продавец” — “ужасный”:\n",
    "w2v_model.wv.most_similar(positive=[\"товар\", \"время\", \"вернуть\"], negative=[\"плохой\"], topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'товар'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#определить наиболее близкое слово из списка к данному слово\n",
    "w2v_model.wv.most_similar_to_given(\"плохой\", [\"товар\", \"продавец\", \"человек\", \"куртка\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_scatterplot(model, word, list_names):\n",
    "    \"\"\"Plot in seaborn the results from the t-SNE dimensionality reduction \n",
    "    algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\"\"\"\n",
    "    vectors_words = [model.wv.word_vec(word)]\n",
    "    word_labels = [word]\n",
    "    color_list = ['red']\n",
    "\n",
    "    close_words = model.wv.most_similar(word)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.word_vec(wrd_score[0])\n",
    "        vectors_words.append(wrd_vector)\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('blue')\n",
    "\n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.word_vec(wrd)\n",
    "        vectors_words.append(wrd_vector)\n",
    "        word_labels.append(wrd)\n",
    "        color_list.append('green')\n",
    "\n",
    "    # t-SNE reduction\n",
    "    Y = (TSNE(n_components=2, random_state=0, perplexity=15, init=\"pca\")\n",
    "        .fit_transform(vectors_words))\n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({\"x\": [x for x in Y[:, 0]],\n",
    "                    \"y\": [y for y in Y[:, 1]],\n",
    "                    \"words\": word_labels,\n",
    "                    \"color\": color_list})\n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                    x=\"x\",\n",
    "                    y=\"y\",\n",
    "                    fit_reg=False,\n",
    "                    marker=\"o\",\n",
    "                    scatter_kws={\"s\": 40,\n",
    "                                \"facecolors\": df[\"color\"]}\n",
    "    )\n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "        p1.text(df[\"x\"][line],\n",
    "                df[\"y\"][line],\n",
    "                \" \" + df[\"words\"][line].title(),\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"bottom\", size=\"medium\",\n",
    "                color=df[\"color\"][line],\n",
    "                weight=\"normal\"\n",
    "        ).set_size(15)\n",
    "\n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "    plt.title('t-SNE visualization for {}'.format(word.title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILLA_0\\AppData\\Local\\Temp\\ipykernel_35944\\3114982501.py:9: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  vectors_words = [model.wv.word_vec(word)]\n",
      "C:\\Users\\ILLA_0\\AppData\\Local\\Temp\\ipykernel_35944\\3114982501.py:15: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  wrd_vector = model.wv.word_vec(wrd_score[0])\n",
      "C:\\Users\\ILLA_0\\AppData\\Local\\Temp\\ipykernel_35944\\3114982501.py:22: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  wrd_vector = model.wv.word_vec(wrd)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtsne_scatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw2v_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mхороший\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mтовар\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mпродавец\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mкуртка\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 29\u001b[0m, in \u001b[0;36mtsne_scatterplot\u001b[1;34m(model, word, list_names)\u001b[0m\n\u001b[0;32m     25\u001b[0m     color_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# t-SNE reduction\u001b[39;00m\n\u001b[0;32m     28\u001b[0m Y \u001b[38;5;241m=\u001b[39m (\u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors_words\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Sets everything up to plot\u001b[39;00m\n\u001b[0;32m     31\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m Y[:, \u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m     32\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: [y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y[:, \u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m     33\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m: word_labels,\n\u001b[0;32m     34\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: color_list})\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1118\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \n\u001b[0;32m   1099\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:828\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tsne_scatterplot(w2v_model, \"хороший\", [\"товар\", \"продавец\", \"куртка\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохой пошив ужасный горловина напере...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдать другой человек получить посылка л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасный синтетик тонкий общий представить карт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар прийти продавец продлить защита мой согл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голый синтетик носить возможно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделать достаточно ткань сделать рисунок замет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>накидка шикарный спасибо большой провдо линять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большой продовца рекомендовать заказат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>очень довольный заказ маленький месяц рб курье...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хороший куртка посторонний запах шов ровный ни...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_ready\n",
       "0      качество плохой пошив ужасный горловина напере...\n",
       "1      товар отдать другой человек получить посылка л...\n",
       "2      ужасный синтетик тонкий общий представить карт...\n",
       "3      товар прийти продавец продлить защита мой согл...\n",
       "4                кофточка голый синтетик носить возможно\n",
       "...                                                  ...\n",
       "89995  сделать достаточно ткань сделать рисунок замет...\n",
       "89996  накидка шикарный спасибо большой провдо линять...\n",
       "89997  спасибо большой продовца рекомендовать заказат...\n",
       "89998  очень довольный заказ маленький месяц рб курье...\n",
       "89999  хороший куртка посторонний запах шов ровный ни...\n",
       "\n",
       "[90000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
